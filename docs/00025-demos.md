# Tracing Examples

For most examples, we'll assume you have two terminals side-by-side:

- One to run the program you want to trace (referred to as tracee).
- One to run your bpftrace and observe the output.

Note that for development cases on OS X, dtrace usage is covered elsewhere.

The source and all of these scripts are available in the [examples folder](https://github.com/dalehamel/usdt-report-doc/tree/gh-pages/examples) of this repository, or from [submodules](https://github.com/dalehamel/usdt-report-doc/tree/gh-pages/src).

## Listing tracepoints

To list tracepoints that you can trace:

```
bpftrace -l 'usdt:*' -p ${PROCESS}
```

## Simple hello world

```{.ruby include=examples/helloworld.rb}
```

This is a basic ruby script that demonstrates the basic use of static tracepoints in Ruby, usin
 the library `ruby-static-tracing` [@ruby-static-tracing] Ruby gem, covered later.

This simplistic program will loop indefinitely, printing `Not Enabled` every second. This represents
the Ruby program going on it's merry way, doing what it's supposed to be doing - pretend that
it is running actual application code. The application isn't spending any time executing probes,
all it is doing is checking if the probe is enabled. Since the probe isn't enabled, it continues
with business as usual. The cost of checking if a probe is enabled is extraordinarily low,
~5 micro seconds).


[![probetest gif](./img/probetest.gif)](https://github.com/dalehamel/usdt-report-doc/blob/gh-pa
es/img/probetest.gif)

This example:

* Creates a provider implicitly through it's reference to 'global', and indicates that it will be firing off an Integer and a String to the tracepoint.
* Registering the tracepoint is like a function declaration - when you fire the tracepoint later, the fire call must match the signature declared by the tracepoint.
* We fetch the the provider that we created, and enable it.
* Enabling the provider loads it into memory, but the tracepoint isn't enabled until it's attached to.

Then, in an infinite loop, we check to see if our tracepoint is enabled, and fire it if it is.

When we run `helloworld.rb`, it will loop and print:

```
Not enabled
Not enabled
Not enabled
```

One line about every second. Not very interesting, right?

When we run our tracing program though:

```
bpftrace -e 'usdt::global:hello_nsec
            { printf("%lld %s\n", arg0, str(arg1))}' -p $(pgrep -f helloworld.rb)
```

Or, using a script:
```
bpftrace ./helloworld.bt -p $(pgrep -f helloworld.rb)
```

`helloworld.bt`:
```{.awk include=examples/helloworld.bt}
```

We'll notice that the output changes to indicate that the probe has been fired:

```
Not enabled
Probe fired!
Probe fired!
Probe fired!
```

And, from our bpftrace process we see:

```
Attaching 1 probe...
55369896776138 Hello world
55370897337512 Hello world
55371897691043 Hello world
```

Upon interrupting our bpftrace with Control+C, the probe stops firing as it is no longer enabled.

This demonstrates:

* How to get data from ruby into our bpftrace using a tracepoint.
* That probes are only enabled when they are attached to.
* How to read integer and string arguments.
* Basic usage of bpftrace with this gem.

In subsequent examples, none of these concepts are covered again.

## Aggregation functions

While the hello world sample above is powerful for debugging, it's basically just a log statement.

To do something a little more interesting, we can use an aggregation function.

bpftrace can generate linear and log2 histograms on map data. Linear histograms show the same
data that is used to construct an ApDex[@appdex]. This type of tracing is good for problems like understanding
request latency.

For this example, we'll use [randist.rb](https://github.com/dalehamel/usdt-report-doc/blob/gh-pages/examples/randist.rb) to analyze a pseudo-random distribution of data.

```{.ruby include=examples/randist.rb}
```

The example should fire out random integers between 0 and 100. We'll see how random it actually is with a linear histogram,
bucketing the results into steps of 10:

```
bpftrace -e 'usdt::global:randist
            {@ = lhist(arg0, 0, 100, 10)}' -p $(pgrep -f ./randist.rb)
Attaching 1 probe...
```

```
@:
[0, 10)      817142 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[10, 20)     815076 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[20, 30)     815205 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[30, 40)     814752 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[40, 50)     815183 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[50, 60)     816676 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[60, 70)     816470 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[70, 80)     815448 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[80, 90)     816913 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[90, 100)    814970 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |

```

There are similar aggregation functions [@bpftrace-reference-guide] for max, mean, count, etc that can be used to summarize large data sets - check them out!

## Latency distributions

This example will profile the function call that we use for getting the current monotonic time in nanoseconds:

```
StaticTracing.nsec
```

Under the hood, this is just calling a libc function to get the current time against a monotonic source. This is how
we calculate the latency in wall-clock time. Since we will be potentially running this quite a lot, we want it to be fast!

For this example, we'll use [nsec.rb](https://github.com/dalehamel/usdt-report-doc/blob/gh-pages/examples/nsec.rb) script to
compute the latency of this call and fire it off in a probe.

```{.ruby include=examples/nsec.rb}
```

Attaching to it with a log2 histogram, we can see that it clusters within a particular latency range:

```
bpftrace -e 'usdt::global:nsec_latency
            {@ = hist(arg0)}' -p $(pgrep -f ./nsec.rb)
Attaching 1 probe...
```

```
@:
[256, 512)            65 |                                                    |
[512, 1K)            162 |@@                                                  |
[1K, 2K)            3647 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[2K, 4K)            3250 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@      |
[4K, 8K)               6 |                                                    |
[8K, 16K)              0 |                                                    |
[16K, 32K)            12 |                                                    |
[32K, 64K)             2 |                                                    |

```

Let's zoom in on that with a linear histogram to get a better idea of the latency distribution:

```
bpftrace -e 'usdt::global:nsec_latency
            {@ = lhist(arg0, 0, 3000, 100)}' -p $(pgrep -f ./nsec.rb)
Attaching 1 probe...
```

```
@:
[300, 400)         1 |                                                    |
[400, 500)        33 |@                                                   |
[500, 600)        50 |@@                                                  |
[600, 700)        49 |@@                                                  |
[700, 800)        42 |@@                                                  |
[800, 900)        21 |@                                                   |
[900, 1000)       15 |                                                    |
[1000, 1100)       9 |                                                    |
[1100, 1200)      11 |                                                    |
[1200, 1300)       4 |                                                    |
[1300, 1400)      16 |                                                    |
[1400, 1500)       9 |                                                    |
[1500, 1600)       7 |                                                    |
[1600, 1700)       8 |                                                    |
[1700, 1800)      70 |@@@                                                 |
[1800, 1900)     419 |@@@@@@@@@@@@@@@@@@@@@                               |
[1900, 2000)     997 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[2000, 2100)     564 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                       |
[2100, 2200)      98 |@@@@@                                               |
[2200, 2300)      37 |@                                                   |
[2300, 2400)      30 |@                                                   |
[2400, 2500)      36 |@                                                   |
[2500, 2600)      46 |@@                                                  |
[2600, 2700)      86 |@@@@                                                |
[2700, 2800)      74 |@@@                                                 |
[2800, 2900)      42 |@@                                                  |
[2900, 3000)      26 |@                                                   |
[3000, ...)       35 |@                                                   |

```

We can see that most of the calls are happening within 1700-2200 nanoseconds, which is pretty blazing fast, around 1-2 microseconds.
Some are faster, and some are slower, representing the long-tails of this distribution, but this can give us confidence that this call will complete quickly.
