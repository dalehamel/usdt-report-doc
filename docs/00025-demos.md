# Tracing Examples

For most examples, we'll assume you have two terminals side-by-side:

- One to run the program you want to trace (referred to as tracee).
- One to run your tracing program and observe the output (bpftrace or dtrace).

We'll give examples of both bpftrace and dtrace invocations that you should be able to paste into a terminal yourself, as well as show you the output.

The source and all of these scripts are available in the [examples folder](https://github.com/dalehamel/usdt-report-doc/tree/gh-pages/examples) of this repository, or from [submodules](https://github.com/dalehamel/usdt-report-doc/tree/gh-pages/src).

## Listing tracepoints

To list tracepoints that you can trace:

On Darwin/OSX:

```
dtrace -l -P "${PROVIDER}${PID}"
```

Using bpftrace: (upstream issue in progress to add similarly functionality to above)

```
bpftrace -l 'usdt:*' -p ${PROCESS}
```

## Simple hello world

```{.ruby include=examples/helloworld.rb}
```

This is a basic ruby script that demonstrates the basic use of static tracepoints in Ruby, using the library `ruby-static-tracing` [@ruby-static-tracing] Ruby gem, covered later.

This simplistic program will loop indefinitely, printing `Not Enabled` every second. This represents the Ruby program going on it's merry way, doing what it's supposed to be doing - pretend that it is running actual application code. The application isn't spending any time executing probes, all it is doing is checking if the probe is enabled. Since the probe isn't enabled, it continues with business as usual. The cost of checking if a probe is enabled is extraordinarily low (~5 micro seconds).


[![probetest gif](./img/probetest.gif)](https://github.com/dalehamel/usdt-report-doc/blob/gh-pages/img/probetest.gif)

This example:

* Creates a provider implicitly through it's reference to 'global', and indicates that it will be firing off an Integer and a String to the tracepoint.
* Registering the tracepoint is like a function declaration - when you fire the tracepoint later, the fire call must match the signature declared by the tracepoint.
* We fetch the the provider that we created, and enable it.
* Enabling the provider loads it into memory, but the tracepoint isn't enabled until it's attached to.

Then, in an infinite loop, we check to see if our tracepoint is enabled, and fire it if it is.

When we run `tock.rb`, it will loop and print:

```
Not enabled
Not enabled
Not enabled
```

One line about every second. Not very interesting, right?

When we run our tracing program though:

With dtrace

```
dtrace -q -n 'global*:::hello_nsec
             { printf("%lld %s\n", arg0, copyinstr(arg1)) }'
```

Or, with dtrace and a script:

```
dtrace -q -s tock.dt
```

`tock.dt`:
```{.awk include=examples/tock.dt}
```

Or, with bpftrace (in production, or in vagrant):

```
bpftrace -e 'usdt::global:hello_nsec
            { printf("%lld %s\n", arg0, str(arg1))}' -p $(pgrep -f ./tock.rb)
```

Or, with bpftrace, using a script:
```
bpftrace ./tock.bt -p $(pgrep -f ./tock.rb)
```

`tock.bt`:
```{.awk include=examples/tock.bt}
```

We'll notice that the output changes to indicate that the probe has been fired:

```
Not enabled
Probe fired!
Probe fired!
Probe fired!
```

And, from our tracing program we see:

```
Attaching 1 probe...
55369896776138 Hello world
55370897337512 Hello world
55371897691043 Hello world
```

Upon interrupting our tracing program with Control+C, the probe stops firing as it is no longer enabled.

This demonstrates:

* How to get data from ruby into our tracing program using a tracepoint.
* That probes are only enabled when they are attached to.
* How to read integer and string arguments.
* Basic usage of bpftrace and dtrace with this gem.

In subsequent examples, none of these concepts are covered again.

## Aggregation functions

While the hello world sample above is powerful for debugging, it's basically just a log statement.

To do something a little more interesting, we can use an aggregation function.

Both bpftrace and dtrace support generating both linear and log2 histograms. Linear histograms show the same
data that is used to construct an ApDex[@appdex]. This type of tracing is good for problems like understanding
request latency.

For this example, we'll use [randist.rb](https://github.com/dalehamel/usdt-report-doc/blob/gh-pages/examples/randist.rb) to analyze a pseudo-random distribution of data.

```{.ruby include=examples/randist.rb}
```


The example should fire out random integers between 0 and 100. We'll see how random it actually is with a linear histogram,
bucketing the results into steps of 10:

```
bpftrace -e 'usdt::global:randist
            {@ = lhist(arg0, 0, 100, 10)}' -p $(pgrep -f ./randist.rb)
Attaching 1 probe...
```

```
@:
[0, 10)      817142 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[10, 20)     815076 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[20, 30)     815205 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[30, 40)     814752 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[40, 50)     815183 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[50, 60)     816676 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[60, 70)     816470 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[70, 80)     815448 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[80, 90)     816913 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |
[90, 100)    814970 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ |

```

It's actually pretty evenly distributed, that's a good sign or a random number generator!

And the results are similar on Darwin [@dtrace-guide-aggregations]:

```
dtrace -q -n 'global*:::randist { @ = lquantize(arg0, 0, 100, 10) }'
```

```
 value  ------------- Distribution ------------- count    
   < 0 |                                         0        
     0 |@@@@                                     145456   
    10 |@@@@                                     145094   
    20 |@@@@                                     145901   
    30 |@@@@                                     145617   
    40 |@@@@                                     145792   
    50 |@@@@                                     145086   
    60 |@@@@                                     146287   
    70 |@@@@                                     146041   
    80 |@@@@                                     145331   
    90 |@@@@                                     145217   
>= 100 |                                         0        

```

Though note the histogram's format and scale are a little different.

There are similar aggregation functions for max, mean, count, etc that can be used to summarize large data sets - check them out!

## Latency distributions

This example will profile the function call that we use for getting the current monotonic time in nanoseconds:

```
StaticTracing.nsec
```

Under the hood, this is just calling a libc function to get the current time against a monotonic source. This is how
we calculate the latency in wall-clock time. Since we will be potentially running this quite a lot, we want it to be fast!



For this example, we'll use [nsec.rb](https://github.com/dalehamel/usdt-report-doc/blob/gh-pages/examples/nsec.rb) script to compute the latency of this call and fire it off in a probe.

```{.ruby include=examples/nsec.rb}
```

Attaching to it with a log2 histogram, we can see that it clusters within a particular latency range:

```
bpftrace -e 'usdt::global:nsec_latency
            {@ = hist(arg0)}' -p $(pgrep -f ./nsec.rb)
Attaching 1 probe...
```

```
@:
[256, 512)            65 |                                                    |
[512, 1K)            162 |@@                                                  |
[1K, 2K)            3647 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[2K, 4K)            3250 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@      |
[4K, 8K)               6 |                                                    |
[8K, 16K)              0 |                                                    |
[16K, 32K)            12 |                                                    |
[32K, 64K)             2 |                                                    |

```

Let's zoom in on that with a linear histogram to get a better idea of the latency distribution:

```
bpftrace -e 'usdt::global:nsec_latency
            {@ = lhist(arg0, 0, 3000, 100)}' -p $(pgrep -f ./nsec.rb)
Attaching 1 probe...
```

```
@:
[300, 400)         1 |                                                    |
[400, 500)        33 |@                                                   |
[500, 600)        50 |@@                                                  |
[600, 700)        49 |@@                                                  |
[700, 800)        42 |@@                                                  |
[800, 900)        21 |@                                                   |
[900, 1000)       15 |                                                    |
[1000, 1100)       9 |                                                    |
[1100, 1200)      11 |                                                    |
[1200, 1300)       4 |                                                    |
[1300, 1400)      16 |                                                    |
[1400, 1500)       9 |                                                    |
[1500, 1600)       7 |                                                    |
[1600, 1700)       8 |                                                    |
[1700, 1800)      70 |@@@                                                 |
[1800, 1900)     419 |@@@@@@@@@@@@@@@@@@@@@                               |
[1900, 2000)     997 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[2000, 2100)     564 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                       |
[2100, 2200)      98 |@@@@@                                               |
[2200, 2300)      37 |@                                                   |
[2300, 2400)      30 |@                                                   |
[2400, 2500)      36 |@                                                   |
[2500, 2600)      46 |@@                                                  |
[2600, 2700)      86 |@@@@                                                |
[2700, 2800)      74 |@@@                                                 |
[2800, 2900)      42 |@@                                                  |
[2900, 3000)      26 |@                                                   |
[3000, ...)       35 |@                                                   |

```

We can see that most of the calls are happening within 1700-2200 nanoseconds, which is pretty blazing fast, around 1-2 microseconds.
Some are faster, and some are slower, representing the long-tails of this distribution, but this can give us confidence that this call will complete quickly.
